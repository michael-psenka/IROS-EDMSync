{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing pairwise synchronization performance between EDM method and ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geoopt\n",
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import scipy.io as spio\n",
    "import open3d as o3d\n",
    "import networkx\n",
    "import os\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# GLOBAL VARS ##################################### \n",
    "# number of points to sample from each view\n",
    "num_points_partviews = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds\n",
    "torch.manual_seed(43)\n",
    "np.random.seed(43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################## DATA COLLECTION ##################################### \n",
    "QQt_ = []\n",
    "bunny_views = []\n",
    "bunny_views_full = []\n",
    "bunny_views_pc = []\n",
    "directory = 'data/bunny/views'\n",
    "for filename in os.listdir(directory):\n",
    "    bunny_view = o3d.io.read_point_cloud(os.path.join(directory,filename))\n",
    "    bunny_view_np = np.asarray(bunny_view.points)\n",
    "    # down-sampled version of point cloud\n",
    "    bunny_view_down = bunny_view_np[np.random.choice(bunny_view_np.shape[0], num_points_partviews, replace=False)]\n",
    "\n",
    "    bunny_view_c = bunny_view_down - np.mean(bunny_view_down, axis=0)\n",
    "    # compute the orthogonal projector for bunny_view\n",
    "    Q, R = np.linalg.qr(bunny_view_c)\n",
    "    QQt_.append(torch.from_numpy(Q @ Q.T).float())\n",
    "    \n",
    "    bunny_views.append(bunny_view_down)\n",
    "    bunny_views_full.append(bunny_view_np)\n",
    "    bunny_views_pc.append(bunny_view)\n",
    "\n",
    "numviews = len(bunny_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(bunny_views[0])\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given input point cloud pc, compute the associated EDM\n",
    "def pointsToDist(pc):\n",
    "    # get size of target EDM\n",
    "    m = pc.shape[0]\n",
    "\n",
    "    # reconstructed PSD matrix\n",
    "    G = pc @ pc.T\n",
    "    diagonal = np.diag(G).reshape(m,1) # column vector of diag entries\n",
    "    # corresponds to 2nd term in Eq (1) of main paper\n",
    "    diagRows = np.tile(diagonal.T, (m, 1))\n",
    "    # corresponds to 1st term in Eq (1) of main paper\n",
    "    diagCols = np.tile(diagonal, (1, m))\n",
    "    return diagRows + diagCols - 2 * G;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Synchronizing two identical copies of one view, where one has randomly permuted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the 3 cases for view1 and view2. Uncomment for different test\n",
    "\n",
    "#### Noiseless case\n",
    "###################\n",
    "view1 = bunny_views[0]\n",
    "P_view_np = np.random.permutation(np.eye(num_points_partviews))\n",
    "P_view = torch.from_numpy(P_view_np).float()\n",
    "view2 = P_view_np.T @ view1\n",
    "\n",
    "#### Noise along manifold\n",
    "###################\n",
    "# view1 = bunny_views[0]\n",
    "# view2 = bunny_views_full[0][np.random.choice(bunny_views_full[0].shape[0], num_points_partviews, replace=False)]\n",
    "# P_view_np = np.zeros((num_points_partviews, num_points_partviews))\n",
    "# ### We use nearest neighbors to construct 'best' association\n",
    "# for j in range(num_points_partviews):\n",
    "#     i = np.argmin(np.sum(np.abs(view1 - view2[j,:])**2,axis=-1))\n",
    "#     P_view_np[i,j] = 1\n",
    "\n",
    "#### Noise in full 3D space\n",
    "###################\n",
    "# view1 = bunny_views[0]\n",
    "# P_view_np = np.random.permutation(np.eye(num_points_partviews))\n",
    "# P_view = torch.from_numpy(P_view_np).float()\n",
    "# view2 = P_view_np.T @ view1\n",
    "\n",
    "# sigma = 0.003\n",
    "# view2 += sigma*np.random.randn(num_points_partviews,3)\n",
    "\n",
    "\n",
    "D_1 = torch.from_numpy(pointsToDist(view1)).float()\n",
    "X_1 = torch.from_numpy(view1).float()\n",
    "D_2 = torch.from_numpy(pointsToDist(view2)).float()\n",
    "X_2_c = view2 - np.mean(view2, axis=0)\n",
    "Q, R = np.linalg.qr(X_2_c)\n",
    "QQt = torch.from_numpy(Q @ Q.T).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.100773811340332\n",
      "0.2223963439464569\n",
      "0.09607978165149689\n",
      "0.06100216880440712\n",
      "0.04453596472740173\n",
      "0.03499339148402214\n",
      "0.02877296321094036\n",
      "0.02439989149570465\n",
      "0.021158941090106964\n",
      "0.018661946058273315\n",
      "0.016679730266332626\n",
      "0.015068350359797478\n",
      "0.013732812367379665\n",
      "0.012608573772013187\n",
      "0.011648519895970821\n",
      "0.010820649564266205\n",
      "0.010098904371261597\n",
      "0.009463608264923096\n",
      "0.008901039138436317\n",
      "0.009750407189130783\n",
      "0.010712912306189537\n",
      "0.01058490015566349\n",
      "0.009950937703251839\n",
      "0.010135426186025143\n",
      "0.009719028137624264\n",
      "0.009160637855529785\n",
      "0.008941132575273514\n",
      "0.008915835060179234\n",
      "0.005484882276505232\n",
      "0.006126316264271736\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# initialize our geoopt manifold we want to optimize over\n",
    "birkhoff = geoopt.manifolds.BirkhoffPolytope(tol=1e-8)\n",
    "# define needed global variables\n",
    "m = num_points_partviews\n",
    "omega = D_2 > 0.004\n",
    "\n",
    "# initialize the manifold parameter. NOTE: the first argument must be on the manifold.\n",
    "# make sure to project explicitly\n",
    "with torch.no_grad():\n",
    "    P = geoopt.ManifoldParameter((1/m)*torch.ones(m, m), manifold=birkhoff).proj_()\n",
    "\n",
    "# the function f(x) we want to minimize is all inside closure()\n",
    "def closure():\n",
    "    optim.zero_grad()\n",
    "    # use this loss for noiseless cases\n",
    "    loss = ((P.t() @ D_1 @ P) - D_2).pow(2).sum()\n",
    "    # use this loss for both noise cases\n",
    "    # loss = ((P.t() @ D_1 @ P) - D_2)[omega].pow(2).sum()\n",
    "\n",
    "    ##### co-planar regularization\n",
    "    # the particular assignment of P_i from global to view\n",
    "    assign = P.t() @ X_1\n",
    "    # centered assignments\n",
    "    assign_c = assign - torch.mean(assign, axis=0)\n",
    "    loss += (assign_c - QQt @ assign_c).pow(2).sum()\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "# define Riemannian GD algorithm\n",
    "optim = geoopt.optim.RiemannianSGD([P], lr=8)\n",
    "\n",
    "# optimize\n",
    "print_step = 100\n",
    "for i in range(3000):\n",
    "    curr_loss = optim.step(closure)\n",
    "    if i % print_step == 0:\n",
    "        print(curr_loss)\n",
    "\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n"
     ]
    }
   ],
   "source": [
    "# Forces row distributions to choose the single element with max probability\n",
    "# This generates the EDM guess for the assignments\n",
    "P_np = P.detach().clone().numpy()\n",
    "\n",
    "for i in range(num_points_partviews):\n",
    "    k = np.argmax(P_np[:,i])\n",
    "    P_np[:,i] = np.zeros(num_points_partviews)\n",
    "    P_np[k,i] = 1\n",
    "\n",
    "# Print percentage of correct points\n",
    "p_EDM = 1 - (1/(2*num_points_partviews))*np.sum(np.abs(P_np - P_view_np))\n",
    "print(p_EDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encapsulates above code. Takes view1 and view2 along with the respective synchronization,\n",
    "# returns the percentage of correct synchronizations.\n",
    "def edm_score(view1, view2, P_view):\n",
    "    D_1 = torch.from_numpy(pointsToDist(view1)).float()\n",
    "    X_1 = torch.from_numpy(view1).float()\n",
    "    D_2 = torch.from_numpy(pointsToDist(view2)).float()\n",
    "    X_2_c = view2 - np.mean(view2, axis=0)\n",
    "    Q, R = np.linalg.qr(X_2_c)\n",
    "    QQt = torch.from_numpy(Q @ Q.T).float()\n",
    "\n",
    "    birkhoff = geoopt.manifolds.BirkhoffPolytope(tol=1e-8)\n",
    "    m = view1.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        P = geoopt.ManifoldParameter((1/m)*torch.ones(m, m), manifold=birkhoff).proj_()\n",
    "\n",
    "\n",
    "    def closure():\n",
    "        optim.zero_grad()\n",
    "        # use this loss for noiseless cases\n",
    "        loss = ((P.t() @ D_1 @ P) - D_2).pow(2).sum()\n",
    "        # use this loss for both noise cases\n",
    "        # loss = ((P.t() @ D_1 @ P) - D_2)[omega].pow(2).sum()\n",
    "\n",
    "        ##### co-planar regularization\n",
    "        # the particular assignment of P_i from global to view\n",
    "        assign = P.t() @ X_1\n",
    "        # centered assignments\n",
    "        assign_c = assign - torch.mean(assign, axis=0)\n",
    "        loss += (assign_c - QQt @ assign_c).pow(2).sum()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "    optim = geoopt.optim.RiemannianSGD([P], lr=8)\n",
    "    print_step = 100\n",
    "    for i in range(1200):\n",
    "        curr_loss = optim.step(closure)\n",
    "        if i % print_step == 0:\n",
    "             print(curr_loss)\n",
    "\n",
    "    P_np = P.detach().clone().numpy()\n",
    "\n",
    "    for i in range(m):\n",
    "        k = np.argmax(P_np[:,i])\n",
    "        P_np[:,i] = np.zeros(m)\n",
    "        P_np[k,i] = 1\n",
    "\n",
    "    # Print percentage of correct points\n",
    "    p_EDM = 1 - (1/(2*m))*np.sum(np.abs(P_np - P_view))\n",
    "    return p_EDM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://github.com/ClayFlannigan/icp\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform that maps corresponding points A to B in m spatial dimensions\n",
    "    Input:\n",
    "      A: Nxm numpy array of corresponding points\n",
    "      B: Nxm numpy array of corresponding points\n",
    "    Returns:\n",
    "      T: (m+1)x(m+1) homogeneous transformation matrix that maps A on to B\n",
    "      R: mxm rotation matrix\n",
    "      t: mx1 translation vector\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    H = np.dot(AA.T, BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "       Vt[m-1,:] *= -1\n",
    "       R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    # homogeneous transformation\n",
    "    T = np.identity(m+1)\n",
    "    T[:m, :m] = R\n",
    "    T[:m, m] = t\n",
    "\n",
    "    return T, R, t\n",
    "\n",
    "\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nxm array of points\n",
    "        dst: Nxm array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances of the nearest neighbor\n",
    "        indices: dst indices of the nearest neighbor\n",
    "    '''\n",
    "\n",
    "    assert src.shape == dst.shape\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=1)\n",
    "    neigh.fit(dst)\n",
    "    distances, indices = neigh.kneighbors(src, return_distance=True)\n",
    "    return distances.ravel(), indices.ravel()\n",
    "\n",
    "\n",
    "def icp(A, B, init_pose=None, max_iterations=2000, tolerance=1e-8):\n",
    "    '''\n",
    "    The Iterative Closest Point method: finds best-fit transform that maps points A on to points B\n",
    "    Input:\n",
    "        A: Nxm numpy array of source mD points\n",
    "        B: Nxm numpy array of destination mD point\n",
    "        init_pose: (m+1)x(m+1) homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation that maps A on to B\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        i: number of iterations to converge\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # make points homogeneous, copy them to maintain the originals\n",
    "    src = np.ones((m+1,A.shape[0]))\n",
    "    dst = np.ones((m+1,B.shape[0]))\n",
    "    src[:m,:] = np.copy(A.T)\n",
    "    dst[:m,:] = np.copy(B.T)\n",
    "\n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbors between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[:m,:].T, dst[:m,:].T)\n",
    "\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_ = best_fit_transform(src[:m,:].T, dst[:m,indices].T)\n",
    "\n",
    "        # update the current source\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.mean(distances)\n",
    "        if np.abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "\n",
    "    # calculate final transformation\n",
    "    _,R,t = best_fit_transform(A, src[:m,:].T)\n",
    "\n",
    "    return R, t, distances, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.124\n"
     ]
    }
   ],
   "source": [
    "# how many distretizations to make for graph\n",
    "refinement = 1\n",
    "# furthest rotation to consider\n",
    "total_dist = np.pi/2\n",
    "# different values for rotation displacement\n",
    "vals = np.zeros(refinement)\n",
    "# percentage correct by ICP on respective rotation\n",
    "p_correct = np.zeros(refinement)\n",
    "\n",
    "for k in range(refinement):\n",
    "    # amount of translation displacement. for now, we assume no displacement\n",
    "    sigma_1 = 0.0086\n",
    "    # angle of displacement for rotation\n",
    "    u = 0.15 * total_dist\n",
    "    vals[k] = u / np.pi\n",
    "    # Generate random rotation. We do this by determining what vector (1,0,0) rotates to\n",
    "    x = np.zeros((3,1))\n",
    "    x[0] = 1\n",
    "    y = np.zeros((3,1))\n",
    "    y[0] = np.cos(u)\n",
    "    y[1] = np.sin(u)\n",
    "\n",
    "    R_init = np.eye(3) + y @ x.T - x @ y.T + (1/(1 + np.inner(x,y)))*np.linalg.matrix_power(y@x.T - x@y.T,2)\n",
    "    # make sure not a reflection\n",
    "    if np.linalg.det(R_init) < 0:\n",
    "        R_init = -1*R_init\n",
    "\n",
    "    ICP_1 = view1\n",
    "    mean = np.mean(view2,axis=0)\n",
    "    ICP_2 = (view2 - mean) @ R_init.T + mean + sigma_1 * np.random.randn(ICP_1.shape[0],3)\n",
    "\n",
    "    R_icp, t_icp, dist, ite = icp(ICP_1, ICP_2, max_iterations=2000, tolerance=1e-8)\n",
    "\n",
    "    # ######### determine the percentage of correct associations via nearest neighbor\n",
    "    mean =  np.mean(ICP_1, axis=0)\n",
    "    ICP_1_fixed = (ICP_1 - mean) @ R_icp.T\n",
    "    # ICP_1_fixed = ICP_1_fixed + mean - t_icp\n",
    "    ICP_2_fixed = ICP_2 - np.mean(ICP_2, axis=0)\n",
    "\n",
    "    P_icp = np.zeros((num_points_partviews, num_points_partviews))\n",
    "    for j in range(num_points_partviews):\n",
    "        i = np.argmin(np.sum(np.abs(ICP_1_fixed - ICP_2_fixed[j,:])**2,axis=-1))\n",
    "        P_icp[i,j] = 1\n",
    "\n",
    "    p_correct[k] = 1 - (1/(2*num_points_partviews))*np.sum(np.abs(P_icp - P_view_np))\n",
    "print(p_correct[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e7ff6d889c46a4bf3180a51aceaee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "f = figure.add_subplot(111, projection='3d')\n",
    "f.scatter(ICP_1_fixed[:,0], ICP_1_fixed[:,1], ICP_1_fixed[:,2], c='r', s = 3)\n",
    "f.scatter(ICP_2_fixed[:,0], ICP_2_fixed[:,1], ICP_2_fixed[:,2], c='b', s = 3)\n",
    "\n",
    "f.set_xlabel('X')\n",
    "f.set_ylabel('Y')\n",
    "f.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Global Registration (FGR)\n",
    "\n",
    "Implementation follows http://www.open3d.org/docs/release/tutorial/Advanced/global_registration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for preparing data for FGR. Additional parameter P for possible permutation of points\n",
    "def preprocess_point_cloud(pcd, voxel_size, *transformation):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    # If specified, transform the downsampled point cloud\n",
    "    if len(transformation) == 1: # just given sigma\n",
    "        sigma = transformation[0]\n",
    "        pcd_np = np.asarray(pcd_down.points)\n",
    "        m = pcd_np.shape[0]\n",
    "        pcd_down.points = o3d.utility.Vector3dVector(pcd_np + sigma*np.random.randn(m,3))\n",
    "    if len(transformation) == 4:\n",
    "        P = transformation[0]\n",
    "        R = transformation[1]\n",
    "        t = transformation[2]\n",
    "        sigma = transformation[3]\n",
    "        \n",
    "        pcd_np = np.asarray(pcd_down.points)\n",
    "        m = pcd_np.shape[0]\n",
    "        pcd_down.points = o3d.utility.Vector3dVector(P.T @ pcd_np + sigma*np.random.randn(m,3))\n",
    "\n",
    "        pcd_down.rotate(R, np.mean(pcd_np, axis=0))\n",
    "\n",
    "        pcd_down.translate(t)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for executing FGR\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.registration.registration_fast_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for drawing the converged result\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "                                    #   zoom=0.4559,\n",
    "                                    #   front=[0.6452, -0.3036, -0.7011],\n",
    "                                    #   lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                    #   up=[-0.2779, -0.9482 ,0.1556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.007.\n",
      ":: Estimate normal with search radius 0.014.\n",
      ":: Compute FPFH feature with search radius 0.035.\n",
      "(33, 767)\n"
     ]
    }
   ],
   "source": [
    "view1_down, view1_fpfh = preprocess_point_cloud(bunny_views_pc[0], voxel_size, sigma)\n",
    "print(view1_fpfh.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.007.\n",
      ":: Estimate normal with search radius 0.014.\n",
      ":: Compute FPFH feature with search radius 0.035.\n",
      "767\n",
      ":: Downsample with a voxel size 0.007.\n",
      ":: Estimate normal with search radius 0.014.\n",
      ":: Compute FPFH feature with search radius 0.035.\n",
      "EDM score w/ noise 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'edm_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cacf7b71f3a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mview2_down\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview2_fpfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_point_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbunny_views_pc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EDM score w/ noise %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medm_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview1_down\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview2_down\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m# start = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mresult_fast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute_fast_global_registration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview1_down\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview2_down\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview1_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview2_fpfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'edm_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Single instance of below comparison graph generator\n",
    "\n",
    "# Note we also set voxel size to be the max sigma\n",
    "# bunny voxel size\n",
    "# voxel_size = 0.0086\n",
    "# dragon voxel size\n",
    "# voxel_size = 0.00947\n",
    "# buddah voxel size\n",
    "# voxel_size = 0.0077\n",
    "# armadillo voxel size\n",
    "voxel_size = 0.00697\n",
    "\n",
    "sigma = voxel_size / 4\n",
    "\n",
    "view1_down, view1_fpfh = preprocess_point_cloud(bunny_views_pc[0], voxel_size, sigma)\n",
    "m = np.asarray(view1_down.points).shape[0]\n",
    "print(m)\n",
    "# Size gotten empirically from running above command\n",
    "P_view = np.random.permutation(np.eye(m))\n",
    "x = np.zeros((3,1))\n",
    "x[0] = 1\n",
    "y = np.zeros((3,1))\n",
    "y[1] = -1\n",
    "y[2] = -0.9\n",
    "y = (1/np.linalg.norm(y)) * y\n",
    "R = np.eye(3) + y @ x.T - x @ y.T + (1/(1 + np.inner(x,y)))*np.linalg.matrix_power(y@x.T - x@y.T,2)\n",
    "t = 0.1*np.ones((3,1))\n",
    "\n",
    "\n",
    "view2_down, view2_fpfh = preprocess_point_cloud(bunny_views_pc[0],voxel_size, P_view, R, t, sigma)\n",
    "print('EDM score w/ noise %d' % (sigma))\n",
    "print(edm_score(np.asarray(view1_down.points), np.asarray(view2_down.points), P_view))\n",
    "# start = time.time()\n",
    "result_fast = execute_fast_global_registration(view1_down, view2_down, view1_fpfh, view2_fpfh, voxel_size)\n",
    "# print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "fgr_corr = np.asarray(result_fast.correspondence_set)\n",
    "total = 0\n",
    "for i in range(fgr_corr.shape[0]):\n",
    "    # check how many assignments truly are valid\n",
    "    total += P_view[fgr_corr[i,0], fgr_corr[i,1]]\n",
    "# NOTE: we always know size=509. Otherwise P_view would return\n",
    "# an error when multiplied through pc\n",
    "\n",
    "print('FGR score w/ noise %d' % (sigma))\n",
    "print(total / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(view1_down, view2_down, result_fast.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.015.\n",
      ":: Estimate normal with search radius 0.030.\n",
      ":: Compute FPFH feature with search radius 0.075.\n",
      "223\n",
      ":: Downsample with a voxel size 0.015.\n",
      ":: Estimate normal with search radius 0.030.\n",
      ":: Compute FPFH feature with search radius 0.075.\n",
      "2.8642725944519043\n",
      "0.08610578626394272\n",
      "0.03545970097184181\n",
      "0.022625071927905083\n",
      "0.016623614355921745\n",
      "0.01311052218079567\n",
      "0.010793756693601608\n",
      "0.009147979319095612\n",
      "0.007917625829577446\n",
      "0.00696287676692009\n",
      "0.006200648378580809\n",
      "0.005578284617513418\n",
      "0.005060834810137749\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9933580a9fa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefinement\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mview2_down\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview2_fpfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_point_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbunny_views_pc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoxel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0medm_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medm_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview1_down\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview2_down\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EDM score w/ noise %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medm_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-4227f1651389>\u001b[0m in \u001b[0;36medm_score\u001b[1;34m(view1, view2, P_view)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mcurr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprint_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m              \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\geoopt\\optim\\rsgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[0mcopy_or_set_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         \u001b[0mnew_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanifold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                         \u001b[0mcopy_or_set_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\geoopt\\manifolds\\birkhoff_polytope.py\u001b[0m in \u001b[0;36mretr\u001b[1;34m(self, x, u)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\geoopt\\manifolds\\birkhoff_polytope.py\u001b[0m in \u001b[0;36mprojx\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprojx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         return proj_doubly_stochastic(\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create graphs of performance vs. noise for EDM vs. FGR\n",
    "\n",
    "# Note we also set voxel size to be the max sigma\n",
    "voxel_size = 0.0086\n",
    "refinement = 10\n",
    "\n",
    "edm_scores = np.zeros(refinement)\n",
    "fgr_scores = np.zeros(refinement)\n",
    "fgr_scores_relative = np.zeros(refinement)\n",
    "\n",
    "view1_down, view1_fpfh = preprocess_point_cloud(bunny_views_pc[0], voxel_size)\n",
    "# Size gotten empirically from running above command\n",
    "P_view = np.random.permutation(np.eye(509))\n",
    "x = np.zeros((3,1))\n",
    "x[0] = 1\n",
    "y = np.zeros((3,1))\n",
    "y[1] = -1\n",
    "y[2] = -0.9\n",
    "y = (1/np.linalg.norm(y)) * y\n",
    "R = np.eye(3) + y @ x.T - x @ y.T + (1/(1 + np.inner(x,y)))*np.linalg.matrix_power(y@x.T - x@y.T,2)\n",
    "t = 0.1*np.ones((3,1))\n",
    "\n",
    "for z in range(refinement):\n",
    "    sigma = z/(refinement-1)*voxel_size\n",
    "    view2_down, view2_fpfh = preprocess_point_cloud(bunny_views_pc[0],voxel_size, P_view, R, t, sigma)\n",
    "    edm_scores[z] = edm_score(np.asarray(view1_down.points), np.asarray(view2_down.points), P_view)\n",
    "    print('EDM score w/ noise %d' % (sigma))\n",
    "    print(edm_scores[z])\n",
    "    # start = time.time()\n",
    "    result_fast = execute_fast_global_registration(view1_down, view2_down, view1_fpfh, view2_fpfh, voxel_size)\n",
    "    # print(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\n",
    "    fgr_corr = np.asarray(result_fast.correspondence_set)\n",
    "    total = 0\n",
    "    for i in range(fgr_corr.shape[0]):\n",
    "        # check how many assignments truly are valid\n",
    "        total += P_view[fgr_corr[i,0], fgr_corr[i,1]]\n",
    "    # NOTE: we always know size=509. Otherwise P_view would return\n",
    "    # an error when multiplied through pc\n",
    "    fgr_scores[z] = total / 509\n",
    "    fgr_scores_relative[z] = total / (fgr_corr.shape[0])\n",
    "\n",
    "    print('FGR score w/ noise %d' % (sigma))\n",
    "    print(fgr_scores[z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69047ac4dff84d3e998f03e0298c330d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edm_scores_fixed = np.zeros(refinement) #accidently scaled by 500, not 509\n",
    "sigmas = np.zeros(refinement)\n",
    "\n",
    "for i in range(refinement):\n",
    "    edm_scores_fixed[i] = 1 - (500/509)*(1 - edm_scores[i])\n",
    "    sigmas[i] = i/(refinement-1)*voxel_size\n",
    "\n",
    "figure = plt.figure()\n",
    "plt.plot(sigmas, fgr_scores)\n",
    "plt.plot(sigmas, edm_scores_fixed)\n",
    "plt.legend(['FGR', 'EDM Method'])\n",
    "plt.xlabel('$\\sigma$')\n",
    "plt.ylabel('% correct associations')\n",
    "# plt.title('Synchronization Performance of ICP by Rotational Separation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([0., 0.00095556, 0.00191111, 0.00286667, 0.00382222, 0.00477778, 0.00573333, 0.00668889, 0.00764444, 0.0086])\n",
    "edm_scores = np.array([0.98428291, 0.94695481, 0.76227898, 0.55009823, 0.33398821, 0.28683694, 0.2043222, 0.15717092, 0.00196464, 0.00196464])\n",
    "fgr_scores = np.array([1., 0.97445972, 0.66601179, 0.21611002, 0., 0.00196464, 0., 0., 0., 0.])\n",
    "icp_scores = np.array([0.982, 0.866, 0.624, 0.45799999999999996, 0.348, 0.256, 0.19399999999999995, 0.16799999999999993, 0.14, 0.124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec12d30d82c482aa0d16a67141082fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure99 = plt.figure()\n",
    "plt.plot(sigmas, fgr_scores, linewidth=3)\n",
    "plt.plot(sigmas, icp_scores, linewidth=3)\n",
    "plt.plot(sigmas, edm_scores, linewidth=3)\n",
    "plt.legend(['FGR', 'ICP', 'EDM Method (ours)'])\n",
    "plt.xlabel('$\\sigma$ of random noise')\n",
    "plt.ylabel('% correct associations')\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# plt.title('Synchronization Performance of ICP by Rotational Separation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4314073b55dd45aba2e8110c9ed76421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure18 = plt.figure()\n",
    "plt.plot(vals, p_correct, linewidth=3)\n",
    "plt.plot(vals, 0.89*np.ones(refinement), linewidth=3)\n",
    "plt.legend(['ICP', 'EDM Method'])\n",
    "plt.xlabel('$\\pi$ radians of rotation')\n",
    "plt.ylabel('% correct associations')\n",
    "# plt.title('Synchronization Performance of ICP by Rotational Separation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python38364bitb674f009352a4dd7b15eec3e44291330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
